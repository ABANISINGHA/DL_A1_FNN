{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "syfrmzt0DPW_"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from keras.datasets import fashion_mnist\n",
        "\n",
        "# Load the Fashion-MNIST dataset\n",
        "(X_train, y_train), (X_test, y_test) = fashion_mnist.load_data()\n",
        "\n",
        "# Define class labels\n",
        "class_labels = {0: \"T-shirt/top\",1: \"Trouser\",2: \"Pullover\",3: \"Dress\",4: \"Coat\",5: \"Sandal\",6: \"Shirt\",7: \"Sneaker\",8: \"Bag\",9: \"Ankle boot\"}\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jD0bUT-aTjYq",
        "outputId": "d7889850-e456-49d0-853e-8daabecfe82d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "29515/29515 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26421880/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "5148/5148 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4422102/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from keras.utils import to_categorical\n",
        "X_train, X_valid, y_train, y_valid = train_test_split(X_train, y_train, test_size=0.2, random_state=42)\n",
        "\n",
        "# Flatten the image data\n",
        "X_train = X_train.reshape(X_train.shape[0], -1)\n",
        "X_valid = X_valid.reshape(X_valid.shape[0], -1)\n",
        "X_test = X_test.reshape(X_test.shape[0], -1)\n",
        "\n",
        "# Normalize the image data\n",
        "X_train = X_train / 255.0\n",
        "X_valid = X_valid / 255.0\n",
        "X_test = X_test / 255.0\n",
        "\n",
        "# Convert labels to one-hot encoding\n",
        "Y_train = to_categorical(y_train)\n",
        "Y_valid = to_categorical(y_valid)\n",
        "Y_test = to_categorical(y_test)\n",
        "print(\"Training images shape:\", X_train.shape)\n",
        "print(\"Training labels shape:\", Y_train.shape)\n",
        "print(\"Training images shape:\", X_valid.shape)\n",
        "print(\"Training labels shape:\", Y_valid.shape)\n",
        "print(\"Testing images shape:\", X_test.shape)\n",
        "print(\"Testing labels shape:\", Y_test.shape)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WuW-fS3MUEQW",
        "outputId": "e9ad1f97-ec6f-43ad-c6da-1e64f8b1f25c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training images shape: (48000, 784)\n",
            "Training labels shape: (48000, 10)\n",
            "Training images shape: (12000, 784)\n",
            "Training labels shape: (12000, 10)\n",
            "Testing images shape: (10000, 784)\n",
            "Testing labels shape: (10000, 10)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "def init_network( num_hidden_layer, num_nodes_hidden_layers, weight, input_size, output_size ):\n",
        "    network_size = []\n",
        "    for i in range(num_hidden_layer):\n",
        "      network_size.append(num_nodes_hidden_layers[i])\n",
        "    size = [input_size] + network_size + [output_size]\n",
        "    theta0 = {}\n",
        "    if weight == 'random':\n",
        "      for i in range(1, num_hidden_layer+2):\n",
        "        theta0['W' + str(i)] = np.random.randn(size[i], size[i-1])\n",
        "        theta0['b' + str(i)] = np.random.randn(size[i], 1)\n",
        "    if weight == 'xavier':\n",
        "      for i in range(1, num_hidden_layer+2):\n",
        "          theta0[\"W\" + str(i)] = np.random.randn(size[i], size[i-1])*(np.sqrt(2/(size[i-1])))\n",
        "          theta0[\"b\" + str(i)] = np.random.randn(size[i], 1)*(np.sqrt(2/(size[i-1])))\n",
        "\n",
        "    return theta0\n",
        "\n",
        "def sigmoid(x):\n",
        "  return 1 / (1 + np.exp(-x))\n",
        "\n",
        "def der_sigmoid(x):\n",
        "  return sigmoid(x)*(1-sigmoid(x))\n",
        "\n",
        "def softmax(x):\n",
        "  x = x - np.max(x)\n",
        "  return np.exp(x)/np.sum(np.exp(x),axis=0)\n",
        "\n",
        "\n",
        "def forword_prop(x,theta, num_hidden_layer,input_size):\n",
        "  a = {}\n",
        "  a['a'+str(0)] = np.zeros((input_size,1))\n",
        "  h = {'h0':x}\n",
        "  for i in range(1,num_hidden_layer+1):\n",
        "    a[\"a\"+str(i)] = np.dot(theta['W'+str(i)],h['h'+str(i-1)]) + theta['b'+str(i)]\n",
        "    h['h'+str(i)] = sigmoid(a[\"a\"+str(i)])\n",
        "  a['a'+str(num_hidden_layer+1)] = np.dot(theta['W'+str(num_hidden_layer+1)],h['h'+str(num_hidden_layer)]) + theta['b'+str(num_hidden_layer+1)]\n",
        "  y_pred = softmax(a['a'+str(num_hidden_layer+1)])\n",
        "\n",
        "  return a,h,y_pred\n",
        "\n",
        "'''\n",
        "def backprop(x, y_actual, num_hidden_layer, theta,input_size):\n",
        "  a,h,y_pred = forword_prop(x,theta, num_hidden_layer,input_size)\n",
        "  grad_W_b = {}\n",
        "  grad_h_a = {}\n",
        "  grad_h_a['a'+str(num_hidden_layer+1)] = -1*(y_actual.T - y_pred)\n",
        "  for i in range(num_hidden_layer+1, 0, -1):\n",
        "    grad_W_b['W'+str(i)] = np.dot(grad_h_a['a'+str(i)],h['h'+str(i-1)].T)\n",
        "    grad_W_b['b'+str(i)] = np.mean(grad_h_a['a'+str(i)],axis = 0, keepdims=True)\n",
        "    grad_h_a['h'+str(i-1)] = np.dot(theta['W'+str(i)].T,grad_h_a['a'+str(i)] )\n",
        "    grad_h_a['a'+str(i-1)] = grad_h_a['h'+str(i-1)]*(der_sigmoid(a['a'+str(i-1)]))\n",
        "\n",
        "  return grad_W_b\n",
        "\n",
        "'''\n",
        "def backprop(x, y_actual, num_hidden_layer, theta, input_size):\n",
        "    m = x.shape[0]\n",
        "    a, h, y_pred = forword_prop(x, theta, num_hidden_layer, input_size)\n",
        "    grad_W_b = {}\n",
        "    grad_h_a = {}\n",
        "    grad_h_a['a' + str(num_hidden_layer + 1)] = -1 * (y_actual.T - y_pred)\n",
        "    for i in range(num_hidden_layer + 1, 0, -1):\n",
        "        grad_W_b['W' + str(i)] = (1/m)*np.dot(grad_h_a['a' + str(i)], h['h' + str(i - 1)].T)\n",
        "        grad_W_b['b' + str(i)] = (1/m)*np.mean(grad_h_a['a' + str(i)], axis=1, keepdims=True)  # Adjusted dimension\n",
        "        grad_h_a['h' + str(i - 1)] = np.dot(theta['W' + str(i)].T, grad_h_a['a' + str(i)])\n",
        "        grad_h_a['a' + str(i - 1)] = grad_h_a['h' + str(i - 1)] * (der_sigmoid(a['a' + str(i - 1)]))\n",
        "\n",
        "    return grad_W_b\n",
        "\n",
        "\n",
        "def gradient_decent(lr, theta, x, y_actual, num_hidden_layer,input_size):\n",
        "  for epoch in range(100):\n",
        "    grad = backprop(x, y_actual, num_hidden_layer, theta,input_size)\n",
        "    for i in range(1, num_hidden_layer+2):\n",
        "      theta['W' + str(i)] -= lr*grad['W' + str(i)]\n",
        "      theta['b' + str(i)] -= lr*grad['b' +str(i)]\n",
        "  return theta\n",
        "\n",
        "\n",
        "def calculate_accuracy(X_test,y_test,theta_new, num_hidden_layer,input_size):\n",
        "  a,h,y_test_pred = forword_prop(X_test,theta_new, num_hidden_layer,input_size)\n",
        "\n",
        "  assert y_test.shape == y_test_pred.shape\n",
        "  y_test = np.argmax(y_test, axis = 0)\n",
        "  y_test_pred = np.argmax(y_test_pred, axis = 0)\n",
        "  correct_predictions = 0\n",
        "  for i in range(y_test.shape[0]):\n",
        "    if y_test[i] == y_test_pred[i]:\n",
        "      correct_predictions += 1\n",
        "  accuracy = correct_predictions /y_test.shape[0] # total_instances\n",
        "\n",
        "  return accuracy\n"
      ],
      "metadata": {
        "id": "kt8q-F_qBRaG"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}